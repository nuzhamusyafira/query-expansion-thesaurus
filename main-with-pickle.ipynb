{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import string\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap dari digilib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paper_ori.pkl', 'rb') as f:\n",
    "    paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_x = [f[0] for f in paper]\n",
    "paper_x = list(set(paper_x))\n",
    "len(paper_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "stemmer = StemmerFactory().create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_paper.pkl', 'rb') as f:\n",
    "    processed_paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate thesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('thesaurus.pkl', 'rb') as f:\n",
    "    thesaurus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x for x in thesaurus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_query = 'deteksi kendaraan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deteksi', 'kendara']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_result = []\n",
    "x = [' '.join(query)]\n",
    "paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "q = paper_tfidf[0]\n",
    "result = cosine_similarity(paper_tfidf, q)\n",
    "idx = np.argsort(-result,axis=0).flatten()    \n",
    "final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "len(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 213\n",
      "QUERY ['deteksi kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 214\n",
      "QUERY ['deteksi kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 76\n",
      "QUERY ['deteksi kendara']\n",
      "FORECASTING NUMBER OF VEHICLE IN ROAD USING MULTILAYER PERCEPTRON NEURAL NETWORK WITH AND WITHOUT LINEAR REGRESSION\n",
      "Jumlah kendaraan yang berada kota-kota besar Indonesia semakin lama semakin bertambah tanpa diimbangi oleh\n",
      "pertambahan jumlah jalan yang sebanding. Setelah beberapa tahun masalah ini tidak ditangani ...\n",
      "\n",
      "Result 77\n",
      "QUERY ['deteksi kendara']\n",
      "FORECASTING NUMBER OF VEHICLE IN ROAD USING MULTILAYER PERCEPTRON NEURAL NETWORK WITH AND WITHOUT LINEAR REGRESSION\n",
      "Jumlah kendaraan yang berada kota-kota besar Indonesia semakin lama semakin bertambah tanpa diimbangi oleh\n",
      "pertambahan jumlah jalan yang sebanding. Setelah beberapa tahun masalah ini tidak ditangani ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in new_result[1:5]: \n",
    "    print('Result', x[0]) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_res = [x[0]-1 for x in new_result[1:]]\n",
    "file = []\n",
    "for i,x in enumerate(paper):\n",
    "    if i in idx_res:\n",
    "        file.append([x[1],x[2],'ok_ok'])\n",
    "    else:\n",
    "        file.append([x[1],x[2],''])\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('hasil/hasil ori ' +init_query+ '.xlsx', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deteksi', 'kendara']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deteksi kendara'] ['deteksi bawa'] ['deteksi naik'] ['deteksi kemudi'] ['deteksi kendali'] ['deteksi gandar'] ['deteksi jalan'] ['deteksi tumpang'] ['deteksi tunggang'] ['deteksi setir'] ['temu kendara'] ['temu bawa'] ['temu naik'] ['temu kemudi'] ['temu kendali'] ['temu gandar'] ['temu jalan'] ['temu tumpang'] ['temu tunggang'] ['temu setir'] ['indra kendara'] ['indra bawa'] ['indra naik'] ['indra kemudi'] ['indra kendali'] ['indra gandar'] ['indra jalan'] ['indra tumpang'] ['indra tunggang'] ['indra setir'] "
     ]
    }
   ],
   "source": [
    "product_query = []\n",
    "list_synonym = []\n",
    "for x in query:\n",
    "    if x in words:\n",
    "        list_synonym.append(thesaurus[x])\n",
    "    else:\n",
    "        name = x\n",
    "        data = { \"q\": name }\n",
    "        encoded_data = urllib.parse.urlencode(data).encode(\"utf-8\")\n",
    "        content = urllib.request.urlopen(\"http://www.sinonimkata.com/search.php\", encoded_data)\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        try:\n",
    "            synonym = soup.find('td', attrs={'width': '90%'}).find_all('a')\n",
    "            synonym = [x.getText() for x in synonym]\n",
    "            thesaurus[x] = [x] + synonym\n",
    "            list_synonym.append(thesaurus[x])\n",
    "        except:\n",
    "            list_synonym.append([x])\n",
    "qs = []\n",
    "for x in itertools.product(*list_synonym):\n",
    "    x = [stemmer.stem(y) for y in x]\n",
    "    qs.append([' '.join(x)])\n",
    "for x in qs:\n",
    "    print(x, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_result = []\n",
    "for x in qs:\n",
    "    paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "    q = paper_tfidf[0]\n",
    "    result = cosine_similarity(paper_tfidf, q)\n",
    "    idx = np.argsort(-result,axis=0).flatten()    \n",
    "    final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "    max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "len(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 214\n",
      "QUERY ['temu kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 215\n",
      "QUERY ['temu kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 311\n",
      "QUERY ['deteksi kendali']\n",
      "CONTROLLING ROBOT BASED ON IP INTERNET\n",
      "PROTOCOL THROUGH THE WIRELESS NETWORK\n",
      "WITH ANDROID MOBILE DEVICE\n",
      "Pengembangan teknologi informasi pada saat ini telah\n",
      "mengalami kemajuan yang sangat pesat khususnya dalam\n",
      "penelitian mengenai sistem jaringan komputer. Salah satu contoh\n",
      "hasil pengembangan teknolog...\n",
      "\n",
      "Result 312\n",
      "QUERY ['deteksi kendali']\n",
      "CONTROLLING ROBOT BASED ON IP INTERNET\n",
      "PROTOCOL THROUGH THE WIRELESS NETWORK\n",
      "WITH ANDROID MOBILE DEVICE\n",
      "Pengembangan teknologi informasi pada saat ini telah\n",
      "mengalami kemajuan yang sangat pesat khususnya dalam\n",
      "penelitian mengenai sistem jaringan komputer. Salah satu contoh\n",
      "hasil pengembangan teknolog...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in new_result[1:5]: \n",
    "    print('Result', x[0]+1) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_res = [x[0]-1 for x in new_result[1:]]\n",
    "file = []\n",
    "for i,x in enumerate(paper):\n",
    "    if i in idx_res:\n",
    "        file.append([x[1],x[2],'ok_ok'])\n",
    "    else:\n",
    "        file.append([x[1],x[2],''])\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('hasil/hasil expansion ' +init_query+ '.xlsx', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
