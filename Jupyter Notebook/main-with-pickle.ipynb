{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import string\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import corpus for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers with abstract found: 328 papers.\n"
     ]
    }
   ],
   "source": [
    "with open('pickle/paper.pkl', 'rb') as f:\n",
    "    paper = pickle.load(f)\n",
    "print(\"Number of papers with abstract found: \" +str(len(paper))+ \" papers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/processed_paper.pkl', 'rb') as f:\n",
    "    processed_paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import words and thesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/words.pkl', 'rb') as f:\n",
    "    words = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/thesaurus.pkl', 'rb') as f:\n",
    "    thesaurus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "stemmer = StemmerFactory().create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1. Query: 'pengembangan aplikasi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert query here\n",
    "\n",
    "init_query = 'pengembangan aplikasi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without query expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query used: kembang aplikasi\n"
     ]
    }
   ],
   "source": [
    "# build tf_idf\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]\n",
    "print(\"Query used: \" +' '.join(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents returned: 212.\n",
      "Top 5 [document, scores, query]:\n",
      "[151, 0.3491994284664284, ['kembang aplikasi']]\n",
      "[152, 0.3491994284664284, ['kembang aplikasi']]\n",
      "[1, 0.23342788528981984, ['kembang aplikasi']]\n",
      "[2, 0.23342788528981984, ['kembang aplikasi']]\n",
      "[310, 0.22871003186602673, ['kembang aplikasi']]\n"
     ]
    }
   ],
   "source": [
    "# process the query\n",
    "\n",
    "max_result = []\n",
    "x = [' '.join(query)]\n",
    "paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "q = paper_tfidf[0]\n",
    "result = cosine_similarity(paper_tfidf, q)\n",
    "idx = np.argsort(-result,axis=0).flatten()    \n",
    "final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "print(\"Number of documents returned: \" +str(len(new_result)-1)+ \".\")\n",
    "print(\"Top 5 [document, scores, query]:\")\n",
    "for x in new_result[1:6]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 151\n",
      "QUERY ['kembang aplikasi']\n",
      "DEVELOPMENT OF A TOOL TO FACILITATE COMMUNICATION AMONG SOFTWARE DEVELOPERS\n",
      "Dalam sebuah proyek pengembangan perangkat lunak yang\n",
      "melibatkan banyak pengembang komunikasi di antara pengembang\n",
      "sangat penting. Komunikasi dilakukan agar para pengembang dapat\n",
      "membantu pekerjaan...\n",
      "\n",
      "Result 152\n",
      "QUERY ['kembang aplikasi']\n",
      "DEVELOPMENT OF A TOOL TO FACILITATE COMMUNICATION AMONG SOFTWARE DEVELOPERS\n",
      "Dalam sebuah proyek pengembangan perangkat lunak yang\n",
      "melibatkan banyak pengembang komunikasi di antara pengembang\n",
      "sangat penting. Komunikasi dilakukan agar para pengembang dapat\n",
      "membantu pekerjaan...\n",
      "\n",
      "Result 1\n",
      "QUERY ['kembang aplikasi']\n",
      "RANCANG BANGUN APLIKASI KOMUNIKASI AUDIO PADA JARINGAN NIRKABEL LOKAL BERBASIS ANDROID MENGGUNAKAN ALGORITMA JOINT CODING RATE CONTROL\n",
      "Perkembangan aplikasi Android dewasa ini sangat pesat aplikasi dikembangkan untuk menyelesaikan permasalahan diberbagai bidang. Saat ini ada beberapa kategori aplikasi Android yang dikembangkan sepert...\n",
      "\n",
      "Result 2\n",
      "QUERY ['kembang aplikasi']\n",
      "DESIGN AND IMPLEMENTATION OF ANDROID BASED AUDIO COMMUNICATION OVER WIRELESS LOCAL NETWORK USING JOINT CODING RATE CONTROL ALGORITHM\n",
      "Perkembangan aplikasi Android dewasa ini sangat pesat aplikasi dikembangkan untuk menyelesaikan permasalahan diberbagai bidang. Saat ini ada beberapa kategori aplikasi Android yang dikembangkan sepert...\n",
      "\n",
      "Result 310\n",
      "QUERY ['kembang aplikasi']\n",
      "CONTROLLING ROBOT BASED ON IP INTERNET\n",
      "PROTOCOL THROUGH THE WIRELESS NETWORK\n",
      "WITH ANDROID MOBILE DEVICE\n",
      "Pengembangan teknologi informasi pada saat ini telah\n",
      "mengalami kemajuan yang sangat pesat khususnya dalam\n",
      "penelitian mengenai sistem jaringan komputer. Salah satu contoh\n",
      "hasil pengembangan teknolog...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 results\n",
    "\n",
    "for x in new_result[1:6]: \n",
    "    print('Result', x[0]) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result to result/pengembangan aplikasi_original.xlsx..\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# save results to 'result/'\n",
    "\n",
    "file = []\n",
    "for x in new_result[1:]:\n",
    "    temp = []\n",
    "    temp.append('Document: ' +str(x[0]))\n",
    "    temp.append('Query: ' +x[2][0])\n",
    "    temp.append('Title: ' +paper[x[0]-1][1])\n",
    "    temp.append(paper[x[0]-1][2])\n",
    "    file.append(temp)\n",
    "\n",
    "print(\"Saving result to result/\" +init_query+ \"_original.xlsx..\")\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('result/' +init_query+ '_original.xlsx', header=False, index=False)\n",
    "print(\"Success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With query expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tf-idf\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries used:\n",
      "- kembang aplikasi\n",
      "- kembang operasi\n",
      "- kembang laksana\n",
      "- kembang terap\n",
      "- kembang guna\n",
      "- kembang praktik\n",
      "- kembang rekayasa\n",
      "- kembang lamar\n",
      "- kembang minta\n",
      "- kembang mohon\n",
      "- bunga aplikasi\n",
      "- bunga operasi\n",
      "- bunga laksana\n",
      "- bunga terap\n",
      "- bunga guna\n",
      "- bunga praktik\n",
      "- bunga rekayasa\n",
      "- bunga lamar\n",
      "- bunga minta\n",
      "- bunga mohon\n",
      "- kesuma aplikasi\n",
      "- kesuma operasi\n",
      "- kesuma laksana\n",
      "- kesuma terap\n",
      "- kesuma guna\n",
      "- kesuma praktik\n",
      "- kesuma rekayasa\n",
      "- kesuma lamar\n",
      "- kesuma minta\n",
      "- kesuma mohon\n",
      "- kusuma aplikasi\n",
      "- kusuma operasi\n",
      "- kusuma laksana\n",
      "- kusuma terap\n",
      "- kusuma guna\n",
      "- kusuma praktik\n",
      "- kusuma rekayasa\n",
      "- kusuma lamar\n",
      "- kusuma minta\n",
      "- kusuma mohon\n",
      "- puspa aplikasi\n",
      "- puspa operasi\n",
      "- puspa laksana\n",
      "- puspa terap\n",
      "- puspa guna\n",
      "- puspa praktik\n",
      "- puspa rekayasa\n",
      "- puspa lamar\n",
      "- puspa minta\n",
      "- puspa mohon\n",
      "- puspita aplikasi\n",
      "- puspita operasi\n",
      "- puspita laksana\n",
      "- puspita terap\n",
      "- puspita guna\n",
      "- puspita praktik\n",
      "- puspita rekayasa\n",
      "- puspita lamar\n",
      "- puspita minta\n",
      "- puspita mohon\n",
      "- sari aplikasi\n",
      "- sari operasi\n",
      "- sari laksana\n",
      "- sari terap\n",
      "- sari guna\n",
      "- sari praktik\n",
      "- sari rekayasa\n",
      "- sari lamar\n",
      "- sari minta\n",
      "- sari mohon\n",
      "- sekar aplikasi\n",
      "- sekar operasi\n",
      "- sekar laksana\n",
      "- sekar terap\n",
      "- sekar guna\n",
      "- sekar praktik\n",
      "- sekar rekayasa\n",
      "- sekar lamar\n",
      "- sekar minta\n",
      "- sekar mohon\n"
     ]
    }
   ],
   "source": [
    "# generate query expansion\n",
    "\n",
    "product_query = []\n",
    "list_synonym = []\n",
    "for x in query:\n",
    "    if x in words:\n",
    "        list_synonym.append(thesaurus[x])\n",
    "    else:\n",
    "        name = x\n",
    "        data = { \"q\": name }\n",
    "        encoded_data = urllib.parse.urlencode(data).encode(\"utf-8\")\n",
    "        content = urllib.request.urlopen(\"http://www.sinonimkata.com/search.php\", encoded_data)\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        try:\n",
    "            synonym = soup.find('td', attrs={'width': '90%'}).find_all('a')\n",
    "            synonym = [x.getText() for x in synonym]\n",
    "            thesaurus[x] = [x] + synonym\n",
    "            list_synonym.append(thesaurus[x])\n",
    "        except:\n",
    "            list_synonym.append([x])\n",
    "qs = []\n",
    "for x in itertools.product(*list_synonym):\n",
    "    x = [stemmer.stem(y) for y in x]\n",
    "    qs.append([' '.join(x)])\n",
    "print(\"Queries used:\")\n",
    "for x in qs:\n",
    "    print(\"-\", x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents returned: 316.\n",
      "Top 5 [document, scores, query]:\n",
      "[151, 0.39806499910346327, ['kembang guna']]\n",
      "[152, 0.39806499910346327, ['kembang guna']]\n",
      "[310, 0.2640909710096908, ['kembang guna']]\n",
      "[311, 0.2640909710096908, ['kembang guna']]\n",
      "[171, 0.26281909713892165, ['kembang rekayasa']]\n"
     ]
    }
   ],
   "source": [
    "# process the query\n",
    "\n",
    "max_result = []\n",
    "for x in qs:\n",
    "    paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "    q = paper_tfidf[0]\n",
    "    result = cosine_similarity(paper_tfidf, q)\n",
    "    idx = np.argsort(-result,axis=0).flatten()    \n",
    "    final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "    max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "print(\"Number of documents returned: \" +str(len(new_result)-1)+ \".\")\n",
    "print(\"Top 5 [document, scores, query]:\")\n",
    "for x in new_result[1:6]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 151\n",
      "QUERY ['kembang guna']\n",
      "DEVELOPMENT OF A TOOL TO FACILITATE COMMUNICATION AMONG SOFTWARE DEVELOPERS\n",
      "Dalam sebuah proyek pengembangan perangkat lunak yang\n",
      "melibatkan banyak pengembang komunikasi di antara pengembang\n",
      "sangat penting. Komunikasi dilakukan agar para pengembang dapat\n",
      "membantu pekerjaan...\n",
      "\n",
      "Result 152\n",
      "QUERY ['kembang guna']\n",
      "DEVELOPMENT OF A TOOL TO FACILITATE COMMUNICATION AMONG SOFTWARE DEVELOPERS\n",
      "Dalam sebuah proyek pengembangan perangkat lunak yang\n",
      "melibatkan banyak pengembang komunikasi di antara pengembang\n",
      "sangat penting. Komunikasi dilakukan agar para pengembang dapat\n",
      "membantu pekerjaan...\n",
      "\n",
      "Result 310\n",
      "QUERY ['kembang guna']\n",
      "CONTROLLING ROBOT BASED ON IP INTERNET\n",
      "PROTOCOL THROUGH THE WIRELESS NETWORK\n",
      "WITH ANDROID MOBILE DEVICE\n",
      "Pengembangan teknologi informasi pada saat ini telah\n",
      "mengalami kemajuan yang sangat pesat khususnya dalam\n",
      "penelitian mengenai sistem jaringan komputer. Salah satu contoh\n",
      "hasil pengembangan teknolog...\n",
      "\n",
      "Result 311\n",
      "QUERY ['kembang guna']\n",
      "CONTROLLING ROBOT BASED ON IP INTERNET\n",
      "PROTOCOL THROUGH THE WIRELESS NETWORK\n",
      "WITH ANDROID MOBILE DEVICE\n",
      "Pengembangan teknologi informasi pada saat ini telah\n",
      "mengalami kemajuan yang sangat pesat khususnya dalam\n",
      "penelitian mengenai sistem jaringan komputer. Salah satu contoh\n",
      "hasil pengembangan teknolog...\n",
      "\n",
      "Result 171\n",
      "QUERY ['kembang rekayasa']\n",
      "THE ITS ACADEMIC INFORMATION SYSTEM ASSESSMENT MODULE REENGINEERING BASED ON FUNCTIONALITY CHARACTERISTIC USING ISOIEC 9126 QUALITY MODEL\n",
      "Sistem Informasi Akademik ITS SIAKAD ITS merupakan sistem pengelolaan kegiatan akademik yang dimiliki oleh Institut Teknologi Sepuluh Nopember Surabaya. Pemeliharaan SIAKAD\n",
      "ITS saat ini belum memilik...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 results\n",
    "\n",
    "for x in new_result[1:6]: \n",
    "    print('Result', x[0]) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result to result/pengembangan aplikasi_expansion.xlsx..\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# save results to 'result/'\n",
    "\n",
    "file = []\n",
    "for x in new_result[1:]:\n",
    "    temp = []\n",
    "    temp.append('Document: ' +str(x[0]))\n",
    "    temp.append('Query: ' +x[2][0])\n",
    "    temp.append('Title: ' +paper[x[0]-1][1])\n",
    "    temp.append(paper[x[0]-1][2])\n",
    "    file.append(temp)\n",
    "\n",
    "print(\"Saving result to result/\" +init_query+ \"_expansion.xlsx..\")\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('result/' +init_query+ '_expansion.xlsx', header=False, index=False)\n",
    "print(\"Success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2. Query: 'pengolahan dokumen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert query here\n",
    "\n",
    "init_query = 'pengolahan dokumen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without query expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query used: olah dokumen\n"
     ]
    }
   ],
   "source": [
    "# build tf_idf\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]\n",
    "print(\"Query used: \" +' '.join(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents returned: 57.\n",
      "Top 5 [document, scores, query]:\n",
      "[143, 0.633286245058755, ['olah dokumen']]\n",
      "[144, 0.633286245058755, ['olah dokumen']]\n",
      "[111, 0.506933668858255, ['olah dokumen']]\n",
      "[112, 0.506933668858255, ['olah dokumen']]\n",
      "[14, 0.5045176176751359, ['olah dokumen']]\n"
     ]
    }
   ],
   "source": [
    "# process the query\n",
    "\n",
    "max_result = []\n",
    "x = [' '.join(query)]\n",
    "paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "q = paper_tfidf[0]\n",
    "result = cosine_similarity(paper_tfidf, q)\n",
    "idx = np.argsort(-result,axis=0).flatten()    \n",
    "final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "print(\"Number of documents returned: \" +str(len(new_result)-1)+ \".\")\n",
    "print(\"Top 5 [document, scores, query]:\")\n",
    "for x in new_result[1:6]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 143\n",
      "QUERY ['olah dokumen']\n",
      "DESIGN OF DOCUMENT GROUPING MODULE IN ADMINISTRATION INFORMATION SYSTEM MANAGEMENTRANCANG\n",
      "Saat ini sudah banyak sekali dokumen-dokumen yang\n",
      "dipublikasikan di internet maupun media lainnya. Dokumen\n",
      "merupakan salah satu produk yang dihasilkan dalam sebuah\n",
      "tatanan organisasi mulai dari per...\n",
      "\n",
      "Result 144\n",
      "QUERY ['olah dokumen']\n",
      "DESIGN OF DOCUMENT GROUPING MODULE IN ADMINISTRATION INFORMATION SYSTEM MANAGEMENTRANCANG\n",
      "Saat ini sudah banyak sekali dokumen-dokumen yang\n",
      "dipublikasikan di internet maupun media lainnya. Dokumen\n",
      "merupakan salah satu produk yang dihasilkan dalam sebuah\n",
      "tatanan organisasi mulai dari per...\n",
      "\n",
      "Result 111\n",
      "QUERY ['olah dokumen']\n",
      "DESIGN PF DOCUMENT TRACKING SYSTEM UTILIZING FUSE AND SAMBA FILE-SYSTEM CASE STUDY IN PT. ANEKA TUNA INDONESIA\n",
      "Saat ini dokumen digital merupakan aspek penting dalam dunia bisnis. Dokumen digital memuat data-data penting\n",
      "perusahaan baik berupa data produksi sampai data keuangan. Dokumen digital dalam perusaha...\n",
      "\n",
      "Result 112\n",
      "QUERY ['olah dokumen']\n",
      "DESIGN PF DOCUMENT TRACKING SYSTEM UTILIZING FUSE AND SAMBA FILE-SYSTEM CASE STUDY IN PT. ANEKA TUNA INDONESIA\n",
      "Saat ini dokumen digital merupakan aspek penting dalam dunia bisnis. Dokumen digital memuat data-data penting\n",
      "perusahaan baik berupa data produksi sampai data keuangan. Dokumen digital dalam perusaha...\n",
      "\n",
      "Result 14\n",
      "QUERY ['olah dokumen']\n",
      "RANCANG BANGUN SISTEM PELACAKAN DOKUMEN MEMANFAATKAN FUSE DAN SAMBA FILE-SYSTEM STUDI KASUS PT. ANEKA TUNA INDONESIA\n",
      "Saat ini dokumen digital merupakan aspek penting dalam\n",
      "dunia bisnis. Dokumen digital memuat data-data penting\n",
      "perusahaan baik berupa data produksi sampai data keuangan.\n",
      "Dokumen digital dalam perusa...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 results\n",
    "\n",
    "for x in new_result[1:6]: \n",
    "    print('Result', x[0]) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result to result/pengolahan dokumen_original.xlsx..\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# save results to 'result/'\n",
    "\n",
    "file = []\n",
    "for x in new_result[1:]:\n",
    "    temp = []\n",
    "    temp.append('Document: ' +str(x[0]))\n",
    "    temp.append('Query: ' +x[2][0])\n",
    "    temp.append('Title: ' +paper[x[0]-1][1])\n",
    "    temp.append(paper[x[0]-1][2])\n",
    "    file.append(temp)\n",
    "\n",
    "print(\"Saving result to result/\" +init_query+ \"_original.xlsx..\")\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('result/' +init_query+ '_original.xlsx', header=False, index=False)\n",
    "print(\"Success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With query expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tf-idf\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries used:\n",
      "- olah dokumen\n",
      "- olah akta\n",
      "- olah arsip\n",
      "- olah inskripsi\n",
      "- olah kopi\n",
      "- olah manuskrip\n",
      "- olah tinggal\n",
      "- olah piagam\n",
      "- olah sahifah\n",
      "- olah salin\n",
      "- olah sertifikat\n",
      "- olah surat\n",
      "- olah tembus\n",
      "- olah tindas\n",
      "- akal dokumen\n",
      "- akal akta\n",
      "- akal arsip\n",
      "- akal inskripsi\n",
      "- akal kopi\n",
      "- akal manuskrip\n",
      "- akal tinggal\n",
      "- akal piagam\n",
      "- akal sahifah\n",
      "- akal salin\n",
      "- akal sertifikat\n",
      "- akal surat\n",
      "- akal tembus\n",
      "- akal tindas\n",
      "- canda dokumen\n",
      "- canda akta\n",
      "- canda arsip\n",
      "- canda inskripsi\n",
      "- canda kopi\n",
      "- canda manuskrip\n",
      "- canda tinggal\n",
      "- canda piagam\n",
      "- canda sahifah\n",
      "- canda salin\n",
      "- canda sertifikat\n",
      "- canda surat\n",
      "- canda tembus\n",
      "- canda tindas\n",
      "- cara dokumen\n",
      "- cara akta\n",
      "- cara arsip\n",
      "- cara inskripsi\n",
      "- cara kopi\n",
      "- cara manuskrip\n",
      "- cara tinggal\n",
      "- cara piagam\n",
      "- cara sahifah\n",
      "- cara salin\n",
      "- cara sertifikat\n",
      "- cara surat\n",
      "- cara tembus\n",
      "- cara tindas\n",
      "- daya dokumen\n",
      "- daya akta\n",
      "- daya arsip\n",
      "- daya inskripsi\n",
      "- daya kopi\n",
      "- daya manuskrip\n",
      "- daya tinggal\n",
      "- daya piagam\n",
      "- daya sahifah\n",
      "- daya salin\n",
      "- daya sertifikat\n",
      "- daya surat\n",
      "- daya tembus\n",
      "- daya tindas\n",
      "- gaya dokumen\n",
      "- gaya akta\n",
      "- gaya arsip\n",
      "- gaya inskripsi\n",
      "- gaya kopi\n",
      "- gaya manuskrip\n",
      "- gaya tinggal\n",
      "- gaya piagam\n",
      "- gaya sahifah\n",
      "- gaya salin\n",
      "- gaya sertifikat\n",
      "- gaya surat\n",
      "- gaya tembus\n",
      "- gaya tindas\n",
      "- laku dokumen\n",
      "- laku akta\n",
      "- laku arsip\n",
      "- laku inskripsi\n",
      "- laku kopi\n",
      "- laku manuskrip\n",
      "- laku tinggal\n",
      "- laku piagam\n",
      "- laku sahifah\n",
      "- laku salin\n",
      "- laku sertifikat\n",
      "- laku surat\n",
      "- laku tembus\n",
      "- laku tindas\n",
      "- lagu dokumen\n",
      "- lagu akta\n",
      "- lagu arsip\n",
      "- lagu inskripsi\n",
      "- lagu kopi\n",
      "- lagu manuskrip\n",
      "- lagu tinggal\n",
      "- lagu piagam\n",
      "- lagu sahifah\n",
      "- lagu salin\n",
      "- lagu sertifikat\n",
      "- lagu surat\n",
      "- lagu tembus\n",
      "- lagu tindas\n",
      "- laku dokumen\n",
      "- laku akta\n",
      "- laku arsip\n",
      "- laku inskripsi\n",
      "- laku kopi\n",
      "- laku manuskrip\n",
      "- laku tinggal\n",
      "- laku piagam\n",
      "- laku sahifah\n",
      "- laku salin\n",
      "- laku sertifikat\n",
      "- laku surat\n",
      "- laku tembus\n",
      "- laku tindas\n",
      "- muslihat dokumen\n",
      "- muslihat akta\n",
      "- muslihat arsip\n",
      "- muslihat inskripsi\n",
      "- muslihat kopi\n",
      "- muslihat manuskrip\n",
      "- muslihat tinggal\n",
      "- muslihat piagam\n",
      "- muslihat sahifah\n",
      "- muslihat salin\n",
      "- muslihat sertifikat\n",
      "- muslihat surat\n",
      "- muslihat tembus\n",
      "- muslihat tindas\n",
      "- perangai dokumen\n",
      "- perangai akta\n",
      "- perangai arsip\n",
      "- perangai inskripsi\n",
      "- perangai kopi\n",
      "- perangai manuskrip\n",
      "- perangai tinggal\n",
      "- perangai piagam\n",
      "- perangai sahifah\n",
      "- perangai salin\n",
      "- perangai sertifikat\n",
      "- perangai surat\n",
      "- perangai tembus\n",
      "- perangai tindas\n",
      "- ragam dokumen\n",
      "- ragam akta\n",
      "- ragam arsip\n",
      "- ragam inskripsi\n",
      "- ragam kopi\n",
      "- ragam manuskrip\n",
      "- ragam tinggal\n",
      "- ragam piagam\n",
      "- ragam sahifah\n",
      "- ragam salin\n",
      "- ragam sertifikat\n",
      "- ragam surat\n",
      "- ragam tembus\n",
      "- ragam tindas\n",
      "- tingkah laku dokumen\n",
      "- tingkah laku akta\n",
      "- tingkah laku arsip\n",
      "- tingkah laku inskripsi\n",
      "- tingkah laku kopi\n",
      "- tingkah laku manuskrip\n",
      "- tingkah laku tinggal\n",
      "- tingkah laku piagam\n",
      "- tingkah laku sahifah\n",
      "- tingkah laku salin\n",
      "- tingkah laku sertifikat\n",
      "- tingkah laku surat\n",
      "- tingkah laku tembus\n",
      "- tingkah laku tindas\n",
      "- ulah dokumen\n",
      "- ulah akta\n",
      "- ulah arsip\n",
      "- ulah inskripsi\n",
      "- ulah kopi\n",
      "- ulah manuskrip\n",
      "- ulah tinggal\n",
      "- ulah piagam\n",
      "- ulah sahifah\n",
      "- ulah salin\n",
      "- ulah sertifikat\n",
      "- ulah surat\n",
      "- ulah tembus\n",
      "- ulah tindas\n"
     ]
    }
   ],
   "source": [
    "# generate query expansion\n",
    "\n",
    "product_query = []\n",
    "list_synonym = []\n",
    "for x in query:\n",
    "    if x in words:\n",
    "        list_synonym.append(thesaurus[x])\n",
    "    else:\n",
    "        name = x\n",
    "        data = { \"q\": name }\n",
    "        encoded_data = urllib.parse.urlencode(data).encode(\"utf-8\")\n",
    "        content = urllib.request.urlopen(\"http://www.sinonimkata.com/search.php\", encoded_data)\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        try:\n",
    "            synonym = soup.find('td', attrs={'width': '90%'}).find_all('a')\n",
    "            synonym = [x.getText() for x in synonym]\n",
    "            thesaurus[x] = [x] + synonym\n",
    "            list_synonym.append(thesaurus[x])\n",
    "        except:\n",
    "            list_synonym.append([x])\n",
    "qs = []\n",
    "for x in itertools.product(*list_synonym):\n",
    "    x = [stemmer.stem(y) for y in x]\n",
    "    qs.append([' '.join(x)])\n",
    "print(\"Queries used:\")\n",
    "for x in qs:\n",
    "    print(\"-\", x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents returned: 278.\n",
      "Top 5 [document, scores, query]:\n",
      "[143, 0.7204574549151622, ['laku dokumen']]\n",
      "[144, 0.7204574549151622, ['laku dokumen']]\n",
      "[111, 0.6042806959241686, ['laku dokumen']]\n",
      "[112, 0.6042806959241686, ['laku dokumen']]\n",
      "[14, 0.6014006683199479, ['laku dokumen']]\n"
     ]
    }
   ],
   "source": [
    "# process the query\n",
    "\n",
    "max_result = []\n",
    "for x in qs:\n",
    "    paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "    q = paper_tfidf[0]\n",
    "    result = cosine_similarity(paper_tfidf, q)\n",
    "    idx = np.argsort(-result,axis=0).flatten()    \n",
    "    final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "    max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "print(\"Number of documents returned: \" +str(len(new_result)-1)+ \".\")\n",
    "print(\"Top 5 [document, scores, query]:\")\n",
    "for x in new_result[1:6]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 143\n",
      "QUERY ['laku dokumen']\n",
      "DESIGN OF DOCUMENT GROUPING MODULE IN ADMINISTRATION INFORMATION SYSTEM MANAGEMENTRANCANG\n",
      "Saat ini sudah banyak sekali dokumen-dokumen yang\n",
      "dipublikasikan di internet maupun media lainnya. Dokumen\n",
      "merupakan salah satu produk yang dihasilkan dalam sebuah\n",
      "tatanan organisasi mulai dari per...\n",
      "\n",
      "Result 144\n",
      "QUERY ['laku dokumen']\n",
      "DESIGN OF DOCUMENT GROUPING MODULE IN ADMINISTRATION INFORMATION SYSTEM MANAGEMENTRANCANG\n",
      "Saat ini sudah banyak sekali dokumen-dokumen yang\n",
      "dipublikasikan di internet maupun media lainnya. Dokumen\n",
      "merupakan salah satu produk yang dihasilkan dalam sebuah\n",
      "tatanan organisasi mulai dari per...\n",
      "\n",
      "Result 111\n",
      "QUERY ['laku dokumen']\n",
      "DESIGN PF DOCUMENT TRACKING SYSTEM UTILIZING FUSE AND SAMBA FILE-SYSTEM CASE STUDY IN PT. ANEKA TUNA INDONESIA\n",
      "Saat ini dokumen digital merupakan aspek penting dalam dunia bisnis. Dokumen digital memuat data-data penting\n",
      "perusahaan baik berupa data produksi sampai data keuangan. Dokumen digital dalam perusaha...\n",
      "\n",
      "Result 112\n",
      "QUERY ['laku dokumen']\n",
      "DESIGN PF DOCUMENT TRACKING SYSTEM UTILIZING FUSE AND SAMBA FILE-SYSTEM CASE STUDY IN PT. ANEKA TUNA INDONESIA\n",
      "Saat ini dokumen digital merupakan aspek penting dalam dunia bisnis. Dokumen digital memuat data-data penting\n",
      "perusahaan baik berupa data produksi sampai data keuangan. Dokumen digital dalam perusaha...\n",
      "\n",
      "Result 14\n",
      "QUERY ['laku dokumen']\n",
      "RANCANG BANGUN SISTEM PELACAKAN DOKUMEN MEMANFAATKAN FUSE DAN SAMBA FILE-SYSTEM STUDI KASUS PT. ANEKA TUNA INDONESIA\n",
      "Saat ini dokumen digital merupakan aspek penting dalam\n",
      "dunia bisnis. Dokumen digital memuat data-data penting\n",
      "perusahaan baik berupa data produksi sampai data keuangan.\n",
      "Dokumen digital dalam perusa...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 results\n",
    "\n",
    "for x in new_result[1:6]: \n",
    "    print('Result', x[0]) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result to result/pengolahan dokumen_expansion.xlsx..\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# save results to 'result/'\n",
    "\n",
    "file = []\n",
    "for x in new_result[1:]:\n",
    "    temp = []\n",
    "    temp.append('Document: ' +str(x[0]))\n",
    "    temp.append('Query: ' +x[2][0])\n",
    "    temp.append('Title: ' +paper[x[0]-1][1])\n",
    "    temp.append(paper[x[0]-1][2])\n",
    "    file.append(temp)\n",
    "\n",
    "print(\"Saving result to result/\" +init_query+ \"_expansion.xlsx..\")\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('result/' +init_query+ '_expansion.xlsx', header=False, index=False)\n",
    "print(\"Success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3. Query: 'deteksi kendaraan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert query here\n",
    "\n",
    "init_query = 'deteksi kendaraan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without query expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query used: deteksi kendara\n"
     ]
    }
   ],
   "source": [
    "# build tf_idf\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]\n",
    "print(\"Query used: \" +' '.join(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents returned: 83.\n",
      "Top 5 [document, scores, query]:\n",
      "[213, 0.34032856938290673, ['deteksi kendara']]\n",
      "[214, 0.34032856938290673, ['deteksi kendara']]\n",
      "[76, 0.2948584016076843, ['deteksi kendara']]\n",
      "[77, 0.2948584016076843, ['deteksi kendara']]\n",
      "[179, 0.26116575798253344, ['deteksi kendara']]\n"
     ]
    }
   ],
   "source": [
    "# process the query\n",
    "\n",
    "max_result = []\n",
    "x = [' '.join(query)]\n",
    "paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "q = paper_tfidf[0]\n",
    "result = cosine_similarity(paper_tfidf, q)\n",
    "idx = np.argsort(-result,axis=0).flatten()    \n",
    "final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "print(\"Number of documents returned: \" +str(len(new_result)-1)+ \".\")\n",
    "print(\"Top 5 [document, scores, query]:\")\n",
    "for x in new_result[1:6]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 213\n",
      "QUERY ['deteksi kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 214\n",
      "QUERY ['deteksi kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 76\n",
      "QUERY ['deteksi kendara']\n",
      "FORECASTING NUMBER OF VEHICLE IN ROAD USING MULTILAYER PERCEPTRON NEURAL NETWORK WITH AND WITHOUT LINEAR REGRESSION\n",
      "Jumlah kendaraan yang berada kota-kota besar Indonesia semakin lama semakin bertambah tanpa diimbangi oleh\n",
      "pertambahan jumlah jalan yang sebanding. Setelah beberapa tahun masalah ini tidak ditangani ...\n",
      "\n",
      "Result 77\n",
      "QUERY ['deteksi kendara']\n",
      "FORECASTING NUMBER OF VEHICLE IN ROAD USING MULTILAYER PERCEPTRON NEURAL NETWORK WITH AND WITHOUT LINEAR REGRESSION\n",
      "Jumlah kendaraan yang berada kota-kota besar Indonesia semakin lama semakin bertambah tanpa diimbangi oleh\n",
      "pertambahan jumlah jalan yang sebanding. Setelah beberapa tahun masalah ini tidak ditangani ...\n",
      "\n",
      "Result 179\n",
      "QUERY ['deteksi kendara']\n",
      "DESIGNING PARKING LOT SECURITY SYSTEM\n",
      "USING SMART GATE\n",
      "Suatu keamanan memang harus dituntut tingkat keamanan\n",
      "yang lebih tinggi khususnya dalam hal ini adalah sistem keamanan\n",
      "tempat parkir. Adanya gangguan  gangguan dari berbagai sistem\n",
      "tempat parkir de...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 results\n",
    "\n",
    "for x in new_result[1:6]: \n",
    "    print('Result', x[0]) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result to result/deteksi kendaraan_original.xlsx..\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# save results to 'result/'\n",
    "\n",
    "file = []\n",
    "for x in new_result[1:]:\n",
    "    temp = []\n",
    "    temp.append('Document: ' +str(x[0]))\n",
    "    temp.append('Query: ' +x[2][0])\n",
    "    temp.append('Title: ' +paper[x[0]-1][1])\n",
    "    temp.append(paper[x[0]-1][2])\n",
    "    file.append(temp)\n",
    "\n",
    "print(\"Saving result to result/\" +init_query+ \"_original.xlsx..\")\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('result/' +init_query+ '_original.xlsx', header=False, index=False)\n",
    "print(\"Success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With query expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tf-idf\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "query = init_query\n",
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries used:\n",
      "- deteksi kendara\n",
      "- deteksi bawa\n",
      "- deteksi naik\n",
      "- deteksi kemudi\n",
      "- deteksi kendali\n",
      "- deteksi gandar\n",
      "- deteksi jalan\n",
      "- deteksi tumpang\n",
      "- deteksi tunggang\n",
      "- deteksi setir\n",
      "- temu kendara\n",
      "- temu bawa\n",
      "- temu naik\n",
      "- temu kemudi\n",
      "- temu kendali\n",
      "- temu gandar\n",
      "- temu jalan\n",
      "- temu tumpang\n",
      "- temu tunggang\n",
      "- temu setir\n",
      "- indra kendara\n",
      "- indra bawa\n",
      "- indra naik\n",
      "- indra kemudi\n",
      "- indra kendali\n",
      "- indra gandar\n",
      "- indra jalan\n",
      "- indra tumpang\n",
      "- indra tunggang\n",
      "- indra setir\n"
     ]
    }
   ],
   "source": [
    "# generate query expansion\n",
    "\n",
    "product_query = []\n",
    "list_synonym = []\n",
    "for x in query:\n",
    "    if x in words:\n",
    "        list_synonym.append(thesaurus[x])\n",
    "    else:\n",
    "        name = x\n",
    "        data = { \"q\": name }\n",
    "        encoded_data = urllib.parse.urlencode(data).encode(\"utf-8\")\n",
    "        content = urllib.request.urlopen(\"http://www.sinonimkata.com/search.php\", encoded_data)\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        try:\n",
    "            synonym = soup.find('td', attrs={'width': '90%'}).find_all('a')\n",
    "            synonym = [x.getText() for x in synonym]\n",
    "            thesaurus[x] = [x] + synonym\n",
    "            list_synonym.append(thesaurus[x])\n",
    "        except:\n",
    "            list_synonym.append([x])\n",
    "qs = []\n",
    "for x in itertools.product(*list_synonym):\n",
    "    x = [stemmer.stem(y) for y in x]\n",
    "    qs.append([' '.join(x)])\n",
    "print(\"Queries used:\")\n",
    "for x in qs:\n",
    "    print(\"-\", x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents returned: 185.\n",
      "Top 5 [document, scores, query]:\n",
      "[213, 0.3413036424835403, ['temu kendara']]\n",
      "[214, 0.3413036424835403, ['temu kendara']]\n",
      "[310, 0.3087636172346658, ['deteksi kendali']]\n",
      "[311, 0.3087636172346658, ['deteksi kendali']]\n",
      "[28, 0.29679900475608745, ['deteksi naik']]\n"
     ]
    }
   ],
   "source": [
    "# process the query\n",
    "\n",
    "max_result = []\n",
    "for x in qs:\n",
    "    paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "    q = paper_tfidf[0]\n",
    "    result = cosine_similarity(paper_tfidf, q)\n",
    "    idx = np.argsort(-result,axis=0).flatten()    \n",
    "    final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "    max_result += final\n",
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)\n",
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "print(\"Number of documents returned: \" +str(len(new_result)-1)+ \".\")\n",
    "print(\"Top 5 [document, scores, query]:\")\n",
    "for x in new_result[1:6]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 213\n",
      "QUERY ['temu kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 214\n",
      "QUERY ['temu kendara']\n",
      "PROTOTYPE OF EMISSION TEST DEVICE FOR VEHICLE USING ARDUINO MICROCONTROLLER\n",
      "Belakangan ini Dinas Perhubungan kembali menggalakkan pengujian kendaraan bermotor kepada masyarakat agar masyarakat paham dengan kondisi mesin kendaraannya maupun dampak emisinya terhadap lingkungan ...\n",
      "\n",
      "Result 310\n",
      "QUERY ['deteksi kendali']\n",
      "CONTROLLING ROBOT BASED ON IP INTERNET\n",
      "PROTOCOL THROUGH THE WIRELESS NETWORK\n",
      "WITH ANDROID MOBILE DEVICE\n",
      "Pengembangan teknologi informasi pada saat ini telah\n",
      "mengalami kemajuan yang sangat pesat khususnya dalam\n",
      "penelitian mengenai sistem jaringan komputer. Salah satu contoh\n",
      "hasil pengembangan teknolog...\n",
      "\n",
      "Result 311\n",
      "QUERY ['deteksi kendali']\n",
      "CONTROLLING ROBOT BASED ON IP INTERNET\n",
      "PROTOCOL THROUGH THE WIRELESS NETWORK\n",
      "WITH ANDROID MOBILE DEVICE\n",
      "Pengembangan teknologi informasi pada saat ini telah\n",
      "mengalami kemajuan yang sangat pesat khususnya dalam\n",
      "penelitian mengenai sistem jaringan komputer. Salah satu contoh\n",
      "hasil pengembangan teknolog...\n",
      "\n",
      "Result 28\n",
      "QUERY ['deteksi naik']\n",
      "IMPLEMENTATION OF SIX MINI GAMES MODULES FOR HEART MEISTER GAME SYSTEM ON UNITY 2D BY APPLYING BUILDER PATTERN\n",
      "Heart Meister merupakan permainan sosial pada perangkat smartphone. Permainan Heart Meister bergenre Role Play Game RPG dengan tema fantasi. Permainan ini berfokus pada pertarungan antar pet yang dimi...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 results\n",
    "\n",
    "for x in new_result[1:6]: \n",
    "    print('Result', x[0]) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2][:200] + '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving result to result/deteksi kendaraan_expansion.xlsx..\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "# save results to 'result/'\n",
    "\n",
    "file = []\n",
    "for x in new_result[1:]:\n",
    "    temp = []\n",
    "    temp.append('Document: ' +str(x[0]))\n",
    "    temp.append('Query: ' +x[2][0])\n",
    "    temp.append('Title: ' +paper[x[0]-1][1])\n",
    "    temp.append(paper[x[0]-1][2])\n",
    "    file.append(temp)\n",
    "\n",
    "print(\"Saving result to result/\" +init_query+ \"_expansion.xlsx..\")\n",
    "df = pd.DataFrame(file)\n",
    "df.to_excel('result/' +init_query+ '_expansion.xlsx', header=False, index=False)\n",
    "print(\"Success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
