{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import string\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap dari digilib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_num = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "digilib_url = 'http://digilib.its.ac.id/publisher/51100/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.20paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.89paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.12paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.15paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.00paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:05<00:00,  3.87paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  6.85paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.09paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.14paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  6.95paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.22paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.06paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.08paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.05paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.08paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.23paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.00paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.10paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.19paper/s]\n",
      "paper: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  6.90paper/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,docs_num,20):\n",
    "    page = urllib.request.urlopen(digilib_url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    docs = soup.find_all('span', attrs={'class': 'style5'})\n",
    "    link = []\n",
    "    for x in docs:\n",
    "        try:\n",
    "            link.append(x.find('a').get('href'))\n",
    "        except:\n",
    "            pass\n",
    "    for x in tqdm(link[:20], desc='paper', unit='paper'):\n",
    "        page = urllib.request.urlopen(x)\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        try:\n",
    "            title = soup.find('h2', attrs={'class': 'isi'}).find('i').getText()\n",
    "            abstract = soup.find('span', attrs={'class': 'teks'}).find('p').getText()\n",
    "            paper.append([x, title, abstract])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "stemmer = StemmerFactory().create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "processed_paper = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paper: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 360/360 [00:22<00:00, 15.85paper/s]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(paper, desc='paper', unit='paper'):\n",
    "    text = x[2]\n",
    "    text = text.lower()\n",
    "    remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "    text = text.translate(remove_punctuation_map)\n",
    "    text = stopword.remove(text)\n",
    "    text = text.split()\n",
    "    text = [stemmer.stem(x) for x in text]\n",
    "    processed_paper.append(' '.join(text))\n",
    "    text = list(set(text))\n",
    "    words += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29320"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate thesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesaurus = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 502/502 [07:22<00:00,  1.14word/s]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(words, desc='word', unit='word'):\n",
    "    name = x\n",
    "    data = { \"q\": name }\n",
    "    encoded_data = urllib.parse.urlencode(data).encode(\"utf-8\")\n",
    "    content = urllib.request.urlopen(\"http://www.sinonimkata.com/search.php\", encoded_data)\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    try:\n",
    "        synonym = soup.find('td', attrs={'width': '90%'}).find_all('a')\n",
    "        synonym = [x.getText() for x in synonym]\n",
    "        thesaurus[x] = [x] + synonym\n",
    "    except:\n",
    "        thesaurus[x] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'pengenalan kendaraan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.lower()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "query = query.translate(remove_punctuation_map)\n",
    "query = stopword.remove(query)\n",
    "query = query.split()\n",
    "query = [stemmer.stem(x) for x in query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kenal', 'kendara']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_query = []\n",
    "list_synonym = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in query:\n",
    "    if x in words:\n",
    "        list_synonym.append(thesaurus[x])\n",
    "    else:\n",
    "        name = x\n",
    "        data = { \"q\": name }\n",
    "        encoded_data = urllib.parse.urlencode(data).encode(\"utf-8\")\n",
    "        content = urllib.request.urlopen(\"http://www.sinonimkata.com/search.php\", encoded_data)\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        try:\n",
    "            synonym = soup.find('td', attrs={'width': '90%'}).find_all('a')\n",
    "            synonym = [x.getText() for x in synonym]\n",
    "            thesaurus[x] = [x] + synonym\n",
    "            list_synonym.append(thesaurus[x])\n",
    "        except:\n",
    "            list_synonym.append([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in itertools.product(*list_synonym):\n",
    "    x = [stemmer.stem(y) for y in x]\n",
    "    qs.append([' '.join(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['kenal kendara'],\n",
       " ['kenal bawa'],\n",
       " ['kenal naik'],\n",
       " ['kenal kemudi'],\n",
       " ['kenal kendali'],\n",
       " ['kenal gandar'],\n",
       " ['kenal jalan'],\n",
       " ['kenal tumpang'],\n",
       " ['kenal tunggang'],\n",
       " ['kenal setir'],\n",
       " ['ingat kendara'],\n",
       " ['ingat bawa'],\n",
       " ['ingat naik'],\n",
       " ['ingat kemudi'],\n",
       " ['ingat kendali'],\n",
       " ['ingat gandar'],\n",
       " ['ingat jalan'],\n",
       " ['ingat tumpang'],\n",
       " ['ingat tunggang'],\n",
       " ['ingat setir'],\n",
       " ['nali kendara'],\n",
       " ['nali bawa'],\n",
       " ['nali naik'],\n",
       " ['nali kemudi'],\n",
       " ['nali kendali'],\n",
       " ['nali gandar'],\n",
       " ['nali jalan'],\n",
       " ['nali tumpang'],\n",
       " ['nali tunggang'],\n",
       " ['nali setir'],\n",
       " ['tahu kendara'],\n",
       " ['tahu bawa'],\n",
       " ['tahu naik'],\n",
       " ['tahu kemudi'],\n",
       " ['tahu kendali'],\n",
       " ['tahu gandar'],\n",
       " ['tahu jalan'],\n",
       " ['tahu tumpang'],\n",
       " ['tahu tunggang'],\n",
       " ['tahu setir']]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in qs:\n",
    "    paper_tfidf = vectorizer.fit_transform(x + processed_paper)\n",
    "    q = paper_tfidf[0]\n",
    "    result = cosine_similarity(paper_tfidf, q)\n",
    "    idx = np.argsort(-result,axis=0).flatten()    \n",
    "    final = [[num, y[0], x] for num, y in enumerate(result) if y[0] > 0.0]\n",
    "    max_result += final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = sorted(max_result, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1.0000000000000002, ['kenal kendara']],\n",
       " [12, 0.14360531244025423, ['kenal naik']],\n",
       " [13, 0.14360531244025423, ['kenal naik']],\n",
       " [30, 0.14360531244025423, ['kenal naik']],\n",
       " [31, 0.14360531244025423, ['kenal naik']],\n",
       " [48, 0.14360531244025423, ['kenal naik']],\n",
       " [49, 0.14360531244025423, ['kenal naik']],\n",
       " [66, 0.14360531244025423, ['kenal naik']],\n",
       " [67, 0.14360531244025423, ['kenal naik']],\n",
       " [84, 0.14360531244025423, ['kenal naik']],\n",
       " [85, 0.14360531244025423, ['kenal naik']],\n",
       " [102, 0.14360531244025423, ['kenal naik']],\n",
       " [103, 0.14360531244025423, ['kenal naik']],\n",
       " [120, 0.14360531244025423, ['kenal naik']],\n",
       " [121, 0.14360531244025423, ['kenal naik']],\n",
       " [138, 0.14360531244025423, ['kenal naik']],\n",
       " [139, 0.14360531244025423, ['kenal naik']],\n",
       " [156, 0.14360531244025423, ['kenal naik']],\n",
       " [157, 0.14360531244025423, ['kenal naik']],\n",
       " [174, 0.14360531244025423, ['kenal naik']],\n",
       " [175, 0.14360531244025423, ['kenal naik']],\n",
       " [192, 0.14360531244025423, ['kenal naik']],\n",
       " [193, 0.14360531244025423, ['kenal naik']],\n",
       " [210, 0.14360531244025423, ['kenal naik']],\n",
       " [211, 0.14360531244025423, ['kenal naik']],\n",
       " [228, 0.14360531244025423, ['kenal naik']],\n",
       " [229, 0.14360531244025423, ['kenal naik']],\n",
       " [246, 0.14360531244025423, ['kenal naik']],\n",
       " [247, 0.14360531244025423, ['kenal naik']],\n",
       " [264, 0.14360531244025423, ['kenal naik']],\n",
       " [265, 0.14360531244025423, ['kenal naik']],\n",
       " [282, 0.14360531244025423, ['kenal naik']],\n",
       " [283, 0.14360531244025423, ['kenal naik']],\n",
       " [300, 0.14360531244025423, ['kenal naik']],\n",
       " [301, 0.14360531244025423, ['kenal naik']],\n",
       " [318, 0.14360531244025423, ['kenal naik']],\n",
       " [319, 0.14360531244025423, ['kenal naik']],\n",
       " [336, 0.14360531244025423, ['kenal naik']],\n",
       " [337, 0.14360531244025423, ['kenal naik']],\n",
       " [354, 0.14360531244025423, ['kenal naik']],\n",
       " [355, 0.14360531244025423, ['kenal naik']],\n",
       " [16, 0.11116425875587455, ['kenal jalan']],\n",
       " [17, 0.11116425875587455, ['kenal jalan']],\n",
       " [34, 0.11116425875587455, ['kenal jalan']],\n",
       " [35, 0.11116425875587455, ['kenal jalan']],\n",
       " [52, 0.11116425875587455, ['kenal jalan']],\n",
       " [53, 0.11116425875587455, ['kenal jalan']],\n",
       " [70, 0.11116425875587455, ['kenal jalan']],\n",
       " [71, 0.11116425875587455, ['kenal jalan']],\n",
       " [88, 0.11116425875587455, ['kenal jalan']],\n",
       " [89, 0.11116425875587455, ['kenal jalan']],\n",
       " [106, 0.11116425875587455, ['kenal jalan']],\n",
       " [107, 0.11116425875587455, ['kenal jalan']],\n",
       " [124, 0.11116425875587455, ['kenal jalan']],\n",
       " [125, 0.11116425875587455, ['kenal jalan']],\n",
       " [142, 0.11116425875587455, ['kenal jalan']],\n",
       " [143, 0.11116425875587455, ['kenal jalan']],\n",
       " [160, 0.11116425875587455, ['kenal jalan']],\n",
       " [161, 0.11116425875587455, ['kenal jalan']],\n",
       " [178, 0.11116425875587455, ['kenal jalan']],\n",
       " [179, 0.11116425875587455, ['kenal jalan']],\n",
       " [196, 0.11116425875587455, ['kenal jalan']],\n",
       " [197, 0.11116425875587455, ['kenal jalan']],\n",
       " [214, 0.11116425875587455, ['kenal jalan']],\n",
       " [215, 0.11116425875587455, ['kenal jalan']],\n",
       " [232, 0.11116425875587455, ['kenal jalan']],\n",
       " [233, 0.11116425875587455, ['kenal jalan']],\n",
       " [250, 0.11116425875587455, ['kenal jalan']],\n",
       " [251, 0.11116425875587455, ['kenal jalan']],\n",
       " [268, 0.11116425875587455, ['kenal jalan']],\n",
       " [269, 0.11116425875587455, ['kenal jalan']],\n",
       " [286, 0.11116425875587455, ['kenal jalan']],\n",
       " [287, 0.11116425875587455, ['kenal jalan']],\n",
       " [304, 0.11116425875587455, ['kenal jalan']],\n",
       " [305, 0.11116425875587455, ['kenal jalan']],\n",
       " [322, 0.11116425875587455, ['kenal jalan']],\n",
       " [323, 0.11116425875587455, ['kenal jalan']],\n",
       " [340, 0.11116425875587455, ['kenal jalan']],\n",
       " [341, 0.11116425875587455, ['kenal jalan']],\n",
       " [358, 0.11116425875587455, ['kenal jalan']],\n",
       " [359, 0.11116425875587455, ['kenal jalan']],\n",
       " [18, 0.021086044691723642, ['kenal kendali']],\n",
       " [36, 0.021086044691723642, ['kenal kendali']],\n",
       " [54, 0.021086044691723642, ['kenal kendali']],\n",
       " [72, 0.021086044691723642, ['kenal kendali']],\n",
       " [90, 0.021086044691723642, ['kenal kendali']],\n",
       " [108, 0.021086044691723642, ['kenal kendali']],\n",
       " [126, 0.021086044691723642, ['kenal kendali']],\n",
       " [144, 0.021086044691723642, ['kenal kendali']],\n",
       " [162, 0.021086044691723642, ['kenal kendali']],\n",
       " [180, 0.021086044691723642, ['kenal kendali']],\n",
       " [198, 0.021086044691723642, ['kenal kendali']],\n",
       " [216, 0.021086044691723642, ['kenal kendali']],\n",
       " [234, 0.021086044691723642, ['kenal kendali']],\n",
       " [252, 0.021086044691723642, ['kenal kendali']],\n",
       " [270, 0.021086044691723642, ['kenal kendali']],\n",
       " [288, 0.021086044691723642, ['kenal kendali']],\n",
       " [306, 0.021086044691723642, ['kenal kendali']],\n",
       " [324, 0.021086044691723642, ['kenal kendali']],\n",
       " [342, 0.021086044691723642, ['kenal kendali']],\n",
       " [360, 0.021086044691723642, ['kenal kendali']],\n",
       " [3, 0.01717505357080603, ['kenal kendali']],\n",
       " [4, 0.01717505357080603, ['kenal kendali']],\n",
       " [21, 0.01717505357080603, ['kenal kendali']],\n",
       " [22, 0.01717505357080603, ['kenal kendali']],\n",
       " [39, 0.01717505357080603, ['kenal kendali']],\n",
       " [40, 0.01717505357080603, ['kenal kendali']],\n",
       " [57, 0.01717505357080603, ['kenal kendali']],\n",
       " [58, 0.01717505357080603, ['kenal kendali']],\n",
       " [75, 0.01717505357080603, ['kenal kendali']],\n",
       " [76, 0.01717505357080603, ['kenal kendali']],\n",
       " [93, 0.01717505357080603, ['kenal kendali']],\n",
       " [94, 0.01717505357080603, ['kenal kendali']],\n",
       " [111, 0.01717505357080603, ['kenal kendali']],\n",
       " [112, 0.01717505357080603, ['kenal kendali']],\n",
       " [129, 0.01717505357080603, ['kenal kendali']],\n",
       " [130, 0.01717505357080603, ['kenal kendali']],\n",
       " [147, 0.01717505357080603, ['kenal kendali']],\n",
       " [148, 0.01717505357080603, ['kenal kendali']],\n",
       " [165, 0.01717505357080603, ['kenal kendali']],\n",
       " [166, 0.01717505357080603, ['kenal kendali']],\n",
       " [183, 0.01717505357080603, ['kenal kendali']],\n",
       " [184, 0.01717505357080603, ['kenal kendali']],\n",
       " [201, 0.01717505357080603, ['kenal kendali']],\n",
       " [202, 0.01717505357080603, ['kenal kendali']],\n",
       " [219, 0.01717505357080603, ['kenal kendali']],\n",
       " [220, 0.01717505357080603, ['kenal kendali']],\n",
       " [237, 0.01717505357080603, ['kenal kendali']],\n",
       " [238, 0.01717505357080603, ['kenal kendali']],\n",
       " [255, 0.01717505357080603, ['kenal kendali']],\n",
       " [256, 0.01717505357080603, ['kenal kendali']],\n",
       " [273, 0.01717505357080603, ['kenal kendali']],\n",
       " [274, 0.01717505357080603, ['kenal kendali']],\n",
       " [291, 0.01717505357080603, ['kenal kendali']],\n",
       " [292, 0.01717505357080603, ['kenal kendali']],\n",
       " [309, 0.01717505357080603, ['kenal kendali']],\n",
       " [310, 0.01717505357080603, ['kenal kendali']],\n",
       " [327, 0.01717505357080603, ['kenal kendali']],\n",
       " [328, 0.01717505357080603, ['kenal kendali']],\n",
       " [345, 0.01717505357080603, ['kenal kendali']],\n",
       " [346, 0.01717505357080603, ['kenal kendali']]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_result = set()\n",
    "new_result = []\n",
    "for item in max_result:\n",
    "    if item[0] not in set_result:\n",
    "        set_result.add(item[0])\n",
    "        new_result.append(item)\n",
    "    else:\n",
    "        pass\n",
    "new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 13\n",
      "QUERY ['kenal naik']\n",
      "IMPLEMENTASI ENAM MODUL MINI GAMES DENGAN MENERAPKAN BUILDER PATTERN UNTUK SISTEM PERMAINAN HEART MEISTER PADA UNITY 2D\n",
      "Heart Meister merupakan permainan sosial pada perangkat\n",
      "smartphone. Permainan Heart Meister bergenre Role Play Game RPG\n",
      "dengan tema fantasi. Permainan ini berfokus pada pertarungan antar pet\n",
      "yang dimiliki pemain. Setiap pet memiliki atribut sebagai indikator\n",
      "kekuatannya. Level dari masing-masing atribut bisa dinaikkan dengan\n",
      "menyelesaikan dungeon yang ada. Akan tetapi terkadang pemain ingin\n",
      "menaikkan level dari atribut tersebut secepat mungkin untuk menjadikan\n",
      "pet-nya semakin kuat. Masalah lain yaitu pet yang bukan merupakan pet\n",
      "utama dari pemain akan susah dinaikkan level atributnya karena jarang\n",
      "atau tidak pernah dipakai. Dengan demikian dibutuhkan suatu sistem\n",
      "untuk menaikkan level atribut dari pet secara cepat dan menarik.\n",
      "Modul mini game ini dibuat dengan tujuan untuk memenuhi\n",
      "kebutuhan penaikan level atribut dari pet pada permainan Heart Meister.\n",
      "Masing-masing atribut dari pet dapat dinaikkan dengan jenis mini game\n",
      "yang berbeda. Hasil penaikan level atribut yang didapat berdasarkan\n",
      "berhasil atau tidaknya pemain dalam menyelesaikan mini game.\n",
      "Modul mini games dibangun dengan menerapkan konsep Builder\n",
      "Pattern. Builder pattern digunakan untuk mengatur pembuatan level\n",
      "pada mini game. Dengan penerapan builder pattern ini pembuatan level\n",
      "dari tiap mini game ditangani oleh kelas yang sama. Dengan demikian\n",
      "penerapan builder pattern ini akan memudahkan jika terjadi\n",
      "penambahan level dari mini game.\n",
      "\n",
      "Result 14\n",
      "QUERY ['kenal naik']\n",
      "IMPLEMENTATION OF SIX MINI GAMES MODULES FOR HEART MEISTER GAME SYSTEM ON UNITY 2D BY APPLYING BUILDER PATTERN\n",
      "Heart Meister merupakan permainan sosial pada perangkat\n",
      "smartphone. Permainan Heart Meister bergenre Role Play Game RPG\n",
      "dengan tema fantasi. Permainan ini berfokus pada pertarungan antar pet\n",
      "yang dimiliki pemain. Setiap pet memiliki atribut sebagai indikator\n",
      "kekuatannya. Level dari masing-masing atribut bisa dinaikkan dengan\n",
      "menyelesaikan dungeon yang ada. Akan tetapi terkadang pemain ingin\n",
      "menaikkan level dari atribut tersebut secepat mungkin untuk menjadikan\n",
      "pet-nya semakin kuat. Masalah lain yaitu pet yang bukan merupakan pet\n",
      "utama dari pemain akan susah dinaikkan level atributnya karena jarang\n",
      "atau tidak pernah dipakai. Dengan demikian dibutuhkan suatu sistem\n",
      "untuk menaikkan level atribut dari pet secara cepat dan menarik.\n",
      "Modul mini game ini dibuat dengan tujuan untuk memenuhi\n",
      "kebutuhan penaikan level atribut dari pet pada permainan Heart Meister.\n",
      "Masing-masing atribut dari pet dapat dinaikkan dengan jenis mini game\n",
      "yang berbeda. Hasil penaikan level atribut yang didapat berdasarkan\n",
      "berhasil atau tidaknya pemain dalam menyelesaikan mini game.\n",
      "Modul mini games dibangun dengan menerapkan konsep Builder\n",
      "Pattern. Builder pattern digunakan untuk mengatur pembuatan level\n",
      "pada mini game. Dengan penerapan builder pattern ini pembuatan level\n",
      "dari tiap mini game ditangani oleh kelas yang sama. Dengan demikian\n",
      "penerapan builder pattern ini akan memudahkan jika terjadi\n",
      "penambahan level dari mini game.\n",
      "\n",
      "Result 31\n",
      "QUERY ['kenal naik']\n",
      "IMPLEMENTASI ENAM MODUL MINI GAMES DENGAN MENERAPKAN BUILDER PATTERN UNTUK SISTEM PERMAINAN HEART MEISTER PADA UNITY 2D\n",
      "Heart Meister merupakan permainan sosial pada perangkat\n",
      "smartphone. Permainan Heart Meister bergenre Role Play Game RPG\n",
      "dengan tema fantasi. Permainan ini berfokus pada pertarungan antar pet\n",
      "yang dimiliki pemain. Setiap pet memiliki atribut sebagai indikator\n",
      "kekuatannya. Level dari masing-masing atribut bisa dinaikkan dengan\n",
      "menyelesaikan dungeon yang ada. Akan tetapi terkadang pemain ingin\n",
      "menaikkan level dari atribut tersebut secepat mungkin untuk menjadikan\n",
      "pet-nya semakin kuat. Masalah lain yaitu pet yang bukan merupakan pet\n",
      "utama dari pemain akan susah dinaikkan level atributnya karena jarang\n",
      "atau tidak pernah dipakai. Dengan demikian dibutuhkan suatu sistem\n",
      "untuk menaikkan level atribut dari pet secara cepat dan menarik.\n",
      "Modul mini game ini dibuat dengan tujuan untuk memenuhi\n",
      "kebutuhan penaikan level atribut dari pet pada permainan Heart Meister.\n",
      "Masing-masing atribut dari pet dapat dinaikkan dengan jenis mini game\n",
      "yang berbeda. Hasil penaikan level atribut yang didapat berdasarkan\n",
      "berhasil atau tidaknya pemain dalam menyelesaikan mini game.\n",
      "Modul mini games dibangun dengan menerapkan konsep Builder\n",
      "Pattern. Builder pattern digunakan untuk mengatur pembuatan level\n",
      "pada mini game. Dengan penerapan builder pattern ini pembuatan level\n",
      "dari tiap mini game ditangani oleh kelas yang sama. Dengan demikian\n",
      "penerapan builder pattern ini akan memudahkan jika terjadi\n",
      "penambahan level dari mini game.\n",
      "\n",
      "Result 32\n",
      "QUERY ['kenal naik']\n",
      "IMPLEMENTATION OF SIX MINI GAMES MODULES FOR HEART MEISTER GAME SYSTEM ON UNITY 2D BY APPLYING BUILDER PATTERN\n",
      "Heart Meister merupakan permainan sosial pada perangkat\n",
      "smartphone. Permainan Heart Meister bergenre Role Play Game RPG\n",
      "dengan tema fantasi. Permainan ini berfokus pada pertarungan antar pet\n",
      "yang dimiliki pemain. Setiap pet memiliki atribut sebagai indikator\n",
      "kekuatannya. Level dari masing-masing atribut bisa dinaikkan dengan\n",
      "menyelesaikan dungeon yang ada. Akan tetapi terkadang pemain ingin\n",
      "menaikkan level dari atribut tersebut secepat mungkin untuk menjadikan\n",
      "pet-nya semakin kuat. Masalah lain yaitu pet yang bukan merupakan pet\n",
      "utama dari pemain akan susah dinaikkan level atributnya karena jarang\n",
      "atau tidak pernah dipakai. Dengan demikian dibutuhkan suatu sistem\n",
      "untuk menaikkan level atribut dari pet secara cepat dan menarik.\n",
      "Modul mini game ini dibuat dengan tujuan untuk memenuhi\n",
      "kebutuhan penaikan level atribut dari pet pada permainan Heart Meister.\n",
      "Masing-masing atribut dari pet dapat dinaikkan dengan jenis mini game\n",
      "yang berbeda. Hasil penaikan level atribut yang didapat berdasarkan\n",
      "berhasil atau tidaknya pemain dalam menyelesaikan mini game.\n",
      "Modul mini games dibangun dengan menerapkan konsep Builder\n",
      "Pattern. Builder pattern digunakan untuk mengatur pembuatan level\n",
      "pada mini game. Dengan penerapan builder pattern ini pembuatan level\n",
      "dari tiap mini game ditangani oleh kelas yang sama. Dengan demikian\n",
      "penerapan builder pattern ini akan memudahkan jika terjadi\n",
      "penambahan level dari mini game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in new_result[1:5]: \n",
    "    print('Result', x[0]+1) \n",
    "    print('QUERY', x[2]) \n",
    "    print(paper[x[0]-1][1]) \n",
    "    print(paper[x[0]-1][2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
